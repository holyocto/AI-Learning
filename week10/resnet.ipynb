{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.downsample = nn.Sequential()\n",
    "        if downsample:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = nn.Sequential()\n",
    "        if downsample:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * self.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, config, output_dim, zero_init_residual=False):\n",
    "        super().__init__()\n",
    "        block, n_blocks, channels = config\n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "        self.in_channels = channels[0]\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7,\n",
    "                               stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride=2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride=2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def get_resnet_layer(self, block, n_blocks, channels, stride=1):\n",
    "        layers = []\n",
    "        downsample = self.in_channels != block.expansion * channels\n",
    "\n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        self.in_channels = block.expansion * channels\n",
    "\n",
    "        for _ in range(1, n_blocks):\n",
    "            layers.append(block(self.in_channels, channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def calculate_topk_accuracy(y_pred, y, k=2):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.size(0)\n",
    "        _, top_pred = y_pred.topk(k, dim=1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim=True)\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "\n",
    "        acc_1 = correct_1 / batch_size\n",
    "        acc_k = correct_k / batch_size\n",
    "\n",
    "        return acc_1, acc_k\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
