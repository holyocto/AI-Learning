{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b97557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/39.5 MB 12.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.7/39.5 MB 11.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 7.1/39.5 MB 11.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.4/39.5 MB 12.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.8/39.5 MB 11.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.2/39.5 MB 11.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.5/39.5 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 18.9/39.5 MB 11.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.2/39.5 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.9/39.5 MB 11.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.2/39.5 MB 11.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.6/39.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.9/39.5 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 33.3/39.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/39.5 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.0/39.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 11.6 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8dcb7ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 400, Val: 92, Test: 10\n",
      "\n",
      "train:\n",
      "torch.Size([8, 3, 224, 224])\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 1]) \n",
      "\n",
      "val:\n",
      "torch.Size([8, 3, 224, 224])\n",
      "tensor([1, 1, 0, 1, 1, 1, 0, 1]) \n",
      "\n",
      "test:\n",
      "torch.Size([1, 3, 224, 224])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 1. ImageTransform 클래스\n",
    "class ImageTransform:\n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(resize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase='train'):\n",
    "        return self.data_transform[phase](img)\n",
    "\n",
    "# 2. DogVsCatDataset 클래스\n",
    "class DogVsCatDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None, phase='train'):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = self.transform(img, self.phase)\n",
    "\n",
    "        # PDF 기준: 파일 이름에서 라벨 추출\n",
    "        folder_name = os.path.basename(os.path.dirname(img_path)).lower()\n",
    "        label = 1 if folder_name == 'dog' else 0\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# 3. 데이터 파일 로딩 및 분할\n",
    "cat_dir = './dogs-vs-cats/Cat'\n",
    "dog_dir = './dogs-vs-cats/Dog'\n",
    "\n",
    "cat_images_filepaths = sorted([os.path.join(cat_dir, f) for f in os.listdir(cat_dir)])\n",
    "dog_images_filepaths = sorted([os.path.join(dog_dir, f) for f in os.listdir(dog_dir)])\n",
    "\n",
    "images_filepaths = [*cat_images_filepaths, *dog_images_filepaths]\n",
    "correct_images_filepaths = [f for f in images_filepaths if cv2.imread(f) is not None]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(correct_images_filepaths)\n",
    "\n",
    "train_images_filepaths = correct_images_filepaths[:400]\n",
    "val_images_filepaths = correct_images_filepaths[400:-10]\n",
    "test_images_filepaths = correct_images_filepaths[-10:]\n",
    "\n",
    "# 4. 전처리 및 DataLoader 정의\n",
    "size = 224\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = ImageTransform(resize=size, mean=mean, std=std)\n",
    "\n",
    "train_dataset = DogVsCatDataset(train_images_filepaths, transform=transform, phase='train')\n",
    "val_dataset = DogVsCatDataset(val_images_filepaths, transform=transform, phase='val')\n",
    "test_dataset = DogVsCatDataset(test_images_filepaths, transform=transform, phase='val')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_images_filepaths)}, Val: {len(val_images_filepaths)}, Test: {len(test_images_filepaths)}\\n\")\n",
    "\n",
    "# 5. 디버깅용 출력\n",
    "for images, labels in train_loader:\n",
    "    print(\"train:\")  \n",
    "    print(images.shape)  # torch.Size([8, 3, 224, 224])\n",
    "    print(labels, \"\\n\")        # tensor([...])\n",
    "    break\n",
    "\n",
    "for images, labels in val_loader:\n",
    "    print(\"val:\") \n",
    "    print(images.shape)  # torch.Size([8, 3, 224, 224])\n",
    "    print(labels, \"\\n\")        # tensor([...])\n",
    "    break\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    print(\"test:\") \n",
    "    print(images.shape)  # torch.Size([8, 3, 224, 224])\n",
    "    print(labels)        # tensor([...])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "066533c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label Count: Counter({'dog': 201, 'cat': 199})\n",
      "Val Label Count: Counter({'dog': 47, 'cat': 45})\n",
      "Test Label Count: Counter({'cat': 7, 'dog': 3})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "def count_labels_from_paths(paths):\n",
    "    labels = []\n",
    "    for path in paths:\n",
    "        folder = os.path.basename(os.path.dirname(path)).lower()\n",
    "        label = 'dog' if folder == 'dog' else 'cat'\n",
    "        labels.append(label)\n",
    "    return Counter(labels)\n",
    "\n",
    "# 데이터셋별 라벨 분포 출력\n",
    "print(\"Train Label Count:\", count_labels_from_paths(train_images_filepaths))\n",
    "print(\"Val Label Count:\", count_labels_from_paths(val_images_filepaths))\n",
    "print(\"Test Label Count:\", count_labels_from_paths(test_images_filepaths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4de0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return self.relu(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
